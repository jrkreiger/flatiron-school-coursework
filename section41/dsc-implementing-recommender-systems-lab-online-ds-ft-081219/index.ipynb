{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Recommender Systems - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice creating a recommender system model using surprise. You'll also get the chance to create a more complete recommender system pipeline to obtain the top recommendations for a specific user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "You will be able to:\n",
    "* Fit a recommender system model to a set of data\n",
    "* Create a function that will return the top recommendations for a user\n",
    "* Introduce a new user to a rating matrix and make recommendations for them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the famous 1M movie dataset. It contains a collection of user ratings for many different movies. In the last  lesson, you got exposed to working with Surprise datasets. In this lab, you will also go through the process of reading in a dataset into the Surprise dataset format. To begin with, load the dataset into a pandas dataframe. Determine which columns are necessary for your recommendation system and drop any extraneous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:08:43.413321Z",
     "start_time": "2019-11-14T16:08:42.690268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      "userId       100836 non-null int64\n",
      "movieId      100836 non-null int64\n",
      "rating       100836 non-null float64\n",
      "timestamp    100836 non-null int64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:08:44.284630Z",
     "start_time": "2019-11-14T16:08:44.256506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1        1     4.0\n",
       "1       1        3     4.0\n",
       "2       1        6     4.0\n",
       "3       1       47     5.0\n",
       "4       1       50     5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop unnecessary columns\n",
    "new_df = df.drop('timestamp', axis=1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time to transform the dataset into something compatible with Surprise. In order to do this, you're going to need `Reader` and `Dataset` classes. There's a method in `Dataset` specifically for loading dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:09:30.324525Z",
     "start_time": "2019-11-14T16:09:30.177843Z"
    }
   },
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "\n",
    "# instantiate Reader\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "\n",
    "# load data\n",
    "data = Dataset.load_from_df(new_df, reader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how many users and items we have in our dataset. If using neighborhood-based methods, this will help us determine whether or not we should perform user-user or item-item similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:09:31.656786Z",
     "start_time": "2019-11-14T16:09:31.543552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  610 \n",
      "\n",
      "Number of items:  9724\n"
     ]
    }
   ],
   "source": [
    "dataset = data.build_full_trainset()\n",
    "print('Number of users: ',dataset.n_users,'\\n')\n",
    "print('Number of items: ',dataset.n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the Best Model\n",
    "Now, compare the different models and see which ones perform best. For consistency's sake, use RMSE to evaluate models. Remember to cross-validate! Can you get a model with a higher average RMSE on test data than 0.869?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:09:54.606407Z",
     "start_time": "2019-11-14T16:09:54.601830Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing relevant libraries\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms import SVD\n",
    "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNBaseline\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:14:21.605743Z",
     "start_time": "2019-11-14T16:11:31.501662Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  2.8min finished\n"
     ]
    }
   ],
   "source": [
    "## Perform a gridsearch with SVD\n",
    "# ‚è∞ This cell may take several minutes to run\n",
    "param_grid = {'n_factors':[20,100],'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "grid = GridSearchCV(SVD, param_grid=param_grid, n_jobs = -1, joblib_verbose=5)\n",
    "grid.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:14:37.403252Z",
     "start_time": "2019-11-14T16:14:37.397334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.890330699250083, 'mae': 0.6885499334153863}\n",
      "{'rmse': {'n_factors': 20, 'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}, 'mae': {'n_factors': 20, 'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}}\n"
     ]
    }
   ],
   "source": [
    "# print out optimal parameters for SVD after GridSearch\n",
    "print(grid.best_score)\n",
    "print(grid.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:20:30.081240Z",
     "start_time": "2019-11-14T16:18:59.324799Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/Users/jennykreiger/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "# cross validating with KNNBasic\n",
    "param_grid2 = {'k': [20, 40, 60],\n",
    "              'sim_options': {'name': ['cosine', 'msd', 'pearson']}}\n",
    "\n",
    "grid2 = GridSearchCV(KNNBasic, param_grid2, n_jobs=-1, joblib_verbose=5)\n",
    "grid2.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:21:17.104567Z",
     "start_time": "2019-11-14T16:21:17.096782Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.9407522639346011, 'mae': 0.7185573982531338}\n",
      "{'rmse': {'k': 20, 'sim_options': {'name': 'msd', 'user_based': True}}, 'mae': {'k': 20, 'sim_options': {'name': 'msd', 'user_based': True}}}\n"
     ]
    }
   ],
   "source": [
    "print(grid2.best_score)\n",
    "print(grid2.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:22:37.794770Z",
     "start_time": "2019-11-14T16:22:24.563079Z"
    }
   },
   "outputs": [],
   "source": [
    "knn = KNNBasic(sim_options={'name':'pearson', 'user_based':True})\n",
    "knn_cv = cross_validate(knn, data, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:23:04.512529Z",
     "start_time": "2019-11-14T16:23:04.501869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.97814714, 0.98039909, 0.96782576, 0.96903464, 0.96826106]))\n",
      "('test_mae', array([0.75303123, 0.75766207, 0.74830464, 0.74640941, 0.74953901]))\n",
      "('fit_time', (0.6010491847991943, 0.6458840370178223, 0.6911270618438721, 0.7270822525024414, 0.5571649074554443))\n",
      "('test_time', (1.7629919052124023, 1.8581361770629883, 1.857116937637329, 1.693587303161621, 1.5305609703063965))\n",
      "-----\n",
      "0.972733536292326\n"
     ]
    }
   ],
   "source": [
    "# print out the average RMSE score for the test set\n",
    "for i in knn_cv.items():\n",
    "    print(i)\n",
    "print('-----')\n",
    "print(np.mean(knn_cv['test_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:23:59.657294Z",
     "start_time": "2019-11-14T16:23:44.797928Z"
    }
   },
   "outputs": [],
   "source": [
    "# cross validating with KNNBaseline\n",
    "knn_base = KNNBaseline(sim_options={'name':'pearson', 'user_based':True})\n",
    "knn_base_cv = cross_validate(knn_base, data, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:24:07.549191Z",
     "start_time": "2019-11-14T16:24:07.541313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.87546008, 0.86960876, 0.88497934, 0.87906675, 0.87827871]))\n",
      "('test_mae', array([0.67118546, 0.66344061, 0.67314864, 0.6723243 , 0.67061853]))\n",
      "('fit_time', (0.6806437969207764, 0.9608120918273926, 0.8920571804046631, 0.7949221134185791, 0.6375842094421387))\n",
      "('test_time', (2.7450952529907227, 3.1253371238708496, 2.9490950107574463, 2.483642101287842, 2.2057809829711914))\n",
      "-----\n",
      "0.8774787301749013\n"
     ]
    }
   ],
   "source": [
    "# print out the average score for the test set\n",
    "for i in knn_base_cv.items():\n",
    "    print(i)\n",
    "print('-----')\n",
    "print(np.mean(knn_base_cv['test_rmse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based off these outputs, it seems like the best performing model is the SVD model with n_factors = 50 and a regularization rate of 0.05. Let's use that model to make some predictions. Use that model or if you found one that performs better, feel free to use that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Recommendations\n",
    "\n",
    "This next section is going to involve making recommendations, and it's important that the output for the recommendation is interpretable to people. Rather than returning the movie_id values, it would be far more valuable to return the actual title of the movie. As a first step, let's read in the movies to a dataframe and take a peek at what information we have about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:25:03.541216Z",
     "start_time": "2019-11-14T16:25:03.511316Z"
    }
   },
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv('./ml-latest-small/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:25:03.993602Z",
     "start_time": "2019-11-14T16:25:03.979657Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making simple predictions\n",
    "Just as a reminder, let's look at how you make a prediction for an individual user and item. First, we'll fit the SVD model we had from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:25:17.183158Z",
     "start_time": "2019-11-14T16:25:13.144475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x11e3f2da0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD(n_factors= 50, reg_all=0.05)\n",
    "svd.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:25:20.439574Z",
     "start_time": "2019-11-14T16:25:20.430299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=2, iid=4, r_ui=None, est=2.9589620782634443, details={'was_impossible': False})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.predict(2,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction value is a tuple and each of the values within it can be accessed by way of indexing. Now let's put all of our knowledge of recommendation systems to do something interesting: making predictions for a new user!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining User Ratings \n",
    "\n",
    "It's great that we have working models and everything, but wouldn't it be nice to get to recommendations specifically tailored to your preferences? That's what we'll be doing now. The first step is to create a function that allows students to pick randomly selected movies. The function should present users with a movie and ask them to rate it. If they have not seen the movie, they should be able to skip rating it. \n",
    "\n",
    "The function `movie_rater` should take as parameters:\n",
    "* movie_df : DataFrame - a dataframe containing the movie ids, name of movie, and genres\n",
    "* num : int - number of ratings\n",
    "* genre : string - a specific genre from which to draw movies\n",
    "\n",
    "The function returns:\n",
    "* rating_list : list - a collection of dictionaries in the format of {'userId': int  , 'movieId': int  ,'rating': float  }\n",
    "\n",
    "#### This function is optional, but fun :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:32:31.858655Z",
     "start_time": "2019-11-14T16:32:31.851847Z"
    }
   },
   "outputs": [],
   "source": [
    "def movie_rater(movie_df, num, genre=None):\n",
    "    userID = 1000\n",
    "    rating_list = []\n",
    "    while num > 0:\n",
    "        if genre:\n",
    "            movie = movie_df[movie_df['genres'].str.contains(genre)].sample(1)\n",
    "        else:\n",
    "            movie = movie_df.sample(1)\n",
    "        print(movie)\n",
    "        rating = input('How do you rate this movie on a scale of 1-5, press n if you have not seen :\\n')\n",
    "        if rating == 'n':\n",
    "            continue\n",
    "        else:\n",
    "            rating_one_movie = {'userId':userID,'movieId':movie['movieId'].values[0],'rating':rating}\n",
    "            rating_list.append(rating_one_movie) \n",
    "            num -= 1\n",
    "    return rating_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:32:57.656314Z",
     "start_time": "2019-11-14T16:32:35.523605Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     movieId                   title                  genres\n",
      "643      829  Joe's Apartment (1996)  Comedy|Fantasy|Musical\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId             title                genres\n",
      "5193     8454  Luna Papa (1999)  Comedy|Drama|Fantasy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId                                              title  genres\n",
      "8758   128366  Patton Oswalt: Tragedy Plus Comedy Equals Time...  Comedy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId                     title genres\n",
      "2203     2928  Razor's Edge, The (1984)  Drama\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId                            title  genres\n",
      "2281     3028  Taming of the Shrew, The (1967)  Comedy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId              title        genres\n",
      "7330    77800  Four Lions (2010)  Comedy|Drama\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId      title genres\n",
      "9367   162414  Moonlight  Drama\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "n\n",
      "      movieId                  title  genres\n",
      "1711     2300  Producers, The (1968)  Comedy\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "5\n",
      "      movieId                                              title       genres\n",
      "5266     8645  Maria Full of Grace (Maria, Llena eres de grac...  Crime|Drama\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "\n",
      "      movieId                       title           genres\n",
      "8174   102802  Lords of Salem, The (2012)  Horror|Thriller\n",
      "How do you rate this movie on a scale of 1-5, press n if you have not seen :\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'userId': 1000, 'movieId': 2300, 'rating': '5'},\n",
       " {'userId': 1000, 'movieId': 8645, 'rating': ''},\n",
       " {'userId': 1000, 'movieId': 102802, 'rating': '3'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try out the new function here!\n",
    "movie_rater(df_movies, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're struggling to come up with the above function, you can use this list of user ratings to complete the next segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:33:17.412136Z",
     "start_time": "2019-11-14T16:33:17.406273Z"
    }
   },
   "outputs": [],
   "source": [
    "user_rating = [{'userId': 1000, 'movieId': 55245, 'rating': '5'},\n",
    " {'userId': 1000, 'movieId': 2491, 'rating': '4'},\n",
    " {'userId': 1000, 'movieId': 4718, 'rating': '4'},\n",
    " {'userId': 1000, 'movieId': 5990, 'rating': '3'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions With the New Ratings\n",
    "Now that you have new ratings, you can use them to make predictions for this new user. The proper way this should work is:\n",
    "\n",
    "* add the new ratings to the original ratings DataFrame, read into a Surprise dataset\n",
    "* train a model using the new combined DataFrame\n",
    "* make predictions for the user\n",
    "* order those predictions from highest rated to lowest rated\n",
    "* return the top n recommendations with the text of the actual movie (rather than just the index number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:34:42.581683Z",
     "start_time": "2019-11-14T16:34:42.393790Z"
    }
   },
   "outputs": [],
   "source": [
    "## add the new ratings to the original ratings DataFrame\n",
    "df_exp = new_df.append(user_rating, ignore_index=True)\n",
    "new_data = Dataset.load_from_df(df_exp, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:37:24.570531Z",
     "start_time": "2019-11-14T16:37:23.678181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBaseline at 0x104b84eb8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a model using the new combined DataFrame\n",
    "knn_base = KNNBaseline(sim_options={'name':'pearson', 'user_based':True})\n",
    "knn_base.fit(new_data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:39:24.127061Z",
     "start_time": "2019-11-14T16:39:23.881079Z"
    }
   },
   "outputs": [],
   "source": [
    "# make predictions for the user\n",
    "# you'll probably want to create a list of tuples in the format (movie_id, predicted_score)\n",
    "movie_list = []\n",
    "for m_id in new_df['movieId'].unique():\n",
    "    movie_list.append((m_id, knn_base.predict(1000, m_id)[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:40:03.311221Z",
     "start_time": "2019-11-14T16:40:03.299886Z"
    }
   },
   "outputs": [],
   "source": [
    "# order the predictions from highest to lowest rated\n",
    "ranked_movies = sorted(movie_list, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For the final component of this challenge, it could be useful to create a function `recommended_movies` that takes in the parameters:\n",
    "* `user_ratings` : list - list of tuples formulated as (user_id, movie_id) (should be in order of best to worst for this individual)\n",
    "* `movie_title_df` : DataFrame \n",
    "* `n` : int- number of recommended movies \n",
    "\n",
    "The function should use a for loop to print out each recommended *n* movies in order from best to worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T16:43:02.662157Z",
     "start_time": "2019-11-14T16:43:02.635882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation # 1 : 46    Usual Suspects, The (1995)\n",
      "Name: title, dtype: object \n",
      "\n",
      "Recommendation # 2 : 89    Bottle Rocket (1996)\n",
      "Name: title, dtype: object \n",
      "\n",
      "Recommendation # 3 : 257    Pulp Fiction (1994)\n",
      "Name: title, dtype: object \n",
      "\n",
      "Recommendation # 4 : 314    Forrest Gump (1994)\n",
      "Name: title, dtype: object \n",
      "\n",
      "Recommendation # 5 : 461    Schindler's List (1993)\n",
      "Name: title, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# return the top n recommendations using the \n",
    "def recommended_movies(user_ratings,movie_title_df,n):\n",
    "    for index, rec in enumerate(user_ratings):\n",
    "        title = movie_title_df.loc[movie_title_df['movieId'] == int(rec[0])]['title']\n",
    "        print('Recommendation #', index+1, ':', title, '\\n')    \n",
    "        n -= 1\n",
    "        if n == 0:\n",
    "            break\n",
    "recommended_movies(ranked_movies,df_movies,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up\n",
    "\n",
    "* Try and chain all of the steps together into one function that asks users for ratings for a certain number of movies, then all of the above steps are performed to return the top n recommendations\n",
    "* Make a recommender system that only returns items that come from a specified genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you got the change to implement a collaborative filtering model as well as retrieve recommendations from that model. You also got the opportunity to add your own recommendations to the system to get new recommendations for yourself! Next, you will get exposed to using spark to make recommender systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
